{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbBnzuy+vgZnqgR0UQ1bu5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Hyperparameters"],"metadata":{"id":"H8mWJ9VgH_mi"}},{"cell_type":"code","source":["import warnings\n","\n","# To ignore all warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"_vO77mCHxygP","executionInfo":{"status":"ok","timestamp":1699897364278,"user_tz":360,"elapsed":152,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import numpy as np"],"metadata":{"id":"zDC4jWffIl0e","executionInfo":{"status":"ok","timestamp":1699897365043,"user_tz":360,"elapsed":448,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Linear Regression"],"metadata":{"id":"5lD7FFIBB2Tq"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e--J_t8THiu-","executionInfo":{"status":"ok","timestamp":1699897365044,"user_tz":360,"elapsed":6,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"757211d7-2a0a-4172-abaf-fb7e28b0c3e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration: 'fit_intercept': True, 'positive': True | 'MSE': 819.50, 'Score': 0.98\n","Configuration: 'fit_intercept': True, 'positive': False | 'MSE': 879.27, 'Score': 0.97\n","Configuration: 'fit_intercept': False, 'positive': True | 'MSE': 820.70, 'Score': 0.98\n","Configuration: 'fit_intercept': False, 'positive': False | 'MSE': 882.58, 'Score': 0.97\n","\n","-------------------------\n","Result:\n","Best hyperparameters: {'fit_intercept': True, 'positive': True}\n","Best mean squared error: 819.5\n"]}],"source":["from sklearn.datasets import make_regression\n","\n","# Generating a synthetic dataset with 100 data points\n","X, y = make_regression(n_samples=100, n_features=20, noise=25)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define a list of hyperparameters to tune\n","hyperparameters = {\n","    'fit_intercept': [True, False],\n","    'positive': [True, False]\n","}\n","\n","# Set a large number value as default\n","best_score = np.inf\n","best_params = {}\n","\n","# Perform grid search over the hyperparameters\n","for fit_intercept in hyperparameters['fit_intercept']:\n","    for positive in hyperparameters['positive']:\n","        # Create the model with the current hyperparameters\n","        model = LinearRegression(fit_intercept=fit_intercept, positive=positive)\n","\n","        # Train the model\n","        model.fit(X_train, y_train)\n","\n","        # Make predictions\n","        predictions = model.predict(X_test)\n","\n","        # Calculate the mean squared error (Focus metric)\n","        mse = mean_squared_error(y_test, predictions)\n","\n","        print(f\"Configuration: 'fit_intercept': {fit_intercept}, 'positive': {positive} | 'MSE': {mse:,.2f}, 'Score': {model.score(X_test, y_test):.2f}\")\n","\n","        # Check if this is the best parameter combination\n","        if mse < best_score:\n","            best_score = round(mse, 2)\n","            best_params = {'fit_intercept': fit_intercept, 'positive': positive}\n","\n","print(f\"\\n{'-'*25}\\nResult:\")\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best mean squared error:\", best_score)"]},{"cell_type":"markdown","source":["## Logistic Regression"],"metadata":{"id":"Lrbwy9_qB4gT"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# Generating a synthetic dataset\n","X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define a list of hyperparameters to tune\n","hyperparameters = {\n","    'penalty': ['l1', 'l2'],\n","    'C': [0.001, 0.01, 0.1, 1, 10]\n","}\n","\n","best_accuracy = 0\n","best_params = {}\n","\n","# Perform grid search over the hyperparameters\n","for penalty in hyperparameters['penalty']:\n","    for C in hyperparameters['C']:\n","        # Create the model with the current hyperparameters\n","        model = LogisticRegression(penalty=penalty, C=C, solver='liblinear')\n","\n","        # Train the model\n","        model.fit(X_train, y_train)\n","\n","        # Make predictions\n","        predictions = model.predict(X_test)\n","\n","        # Calculate accuracy\n","        accuracy = accuracy_score(y_test, predictions)\n","\n","        print(f\"Configuration: 'penalty': {penalty}, 'C': {C} | 'Accuracy': {accuracy:.2f}\")\n","\n","        # Check if this is the best parameter combination\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","            best_params = {'penalty': penalty, 'C': C}\n","\n","print(f\"\\n{'-'*25}\\nResult:\")\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best accuracy:\", best_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5eOtrws2Bnsj","executionInfo":{"status":"ok","timestamp":1699897365044,"user_tz":360,"elapsed":4,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"44c85af9-fde5-4b46-dfde-43e9cc9aef4a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration: 'penalty': l1, 'C': 0.001 | 'Accuracy': 0.56\n","Configuration: 'penalty': l1, 'C': 0.01 | 'Accuracy': 0.77\n","Configuration: 'penalty': l1, 'C': 0.1 | 'Accuracy': 0.83\n","Configuration: 'penalty': l1, 'C': 1 | 'Accuracy': 0.83\n","Configuration: 'penalty': l1, 'C': 10 | 'Accuracy': 0.83\n","Configuration: 'penalty': l2, 'C': 0.001 | 'Accuracy': 0.80\n","Configuration: 'penalty': l2, 'C': 0.01 | 'Accuracy': 0.82\n","Configuration: 'penalty': l2, 'C': 0.1 | 'Accuracy': 0.83\n","Configuration: 'penalty': l2, 'C': 1 | 'Accuracy': 0.83\n","Configuration: 'penalty': l2, 'C': 10 | 'Accuracy': 0.83\n","\n","-------------------------\n","Result:\n","Best hyperparameters: {'penalty': 'l1', 'C': 1}\n","Best accuracy: 0.835\n"]}]},{"cell_type":"markdown","source":["## Decision Tree Classifier"],"metadata":{"id":"Vgftw2b1qxlw"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Generating a synthetic dataset\n","X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define a list of hyperparameters to tune\n","hyperparameters = {\n","    'criterion': ['gini', 'entropy'],\n","    'max_depth': [None, 5, 10, 15],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","best_accuracy = 0\n","best_params = {}\n","\n","# Perform grid search over the hyperparameters\n","for criterion in hyperparameters['criterion']:\n","    for max_depth in hyperparameters['max_depth']:\n","        for min_samples_split in hyperparameters['min_samples_split']:\n","            for min_samples_leaf in hyperparameters['min_samples_leaf']:\n","                # Create the model with the current hyperparameters\n","                model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth,\n","                                               min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n","\n","                # Train the model\n","                model.fit(X_train, y_train)\n","\n","                # Make predictions\n","                predictions = model.predict(X_test)\n","\n","                # Calculate accuracy\n","                accuracy = accuracy_score(y_test, predictions)\n","\n","                print(f\"Configuration: 'criterion': {criterion}, 'max_depth': {max_depth}, 'min_samples_split': {min_samples_split}, 'min_samples_leaf': {min_samples_leaf} | 'Accuracy': {accuracy:.2f}\")\n","\n","                # Check if this is the best parameter combination\n","                if accuracy > best_accuracy:\n","                    best_accuracy = accuracy\n","                    best_params = {'criterion': criterion, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n","\n","print(f\"\\n{'-'*25}\\nResult:\")\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best accuracy:\", best_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cwv4gUAXq7kU","executionInfo":{"status":"ok","timestamp":1699897365822,"user_tz":360,"elapsed":780,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"8c11da39-fa04-4448-cdb7-8cab8c2880db"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration: 'criterion': gini, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1 | 'Accuracy': 0.90\n","Configuration: 'criterion': gini, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2 | 'Accuracy': 0.90\n","Configuration: 'criterion': gini, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 4 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1 | 'Accuracy': 0.90\n","Configuration: 'criterion': gini, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 4 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': gini, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1 | 'Accuracy': 0.92\n","Configuration: 'criterion': gini, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2 | 'Accuracy': 0.92\n","Configuration: 'criterion': gini, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1 | 'Accuracy': 0.90\n","Configuration: 'criterion': gini, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2 | 'Accuracy': 0.90\n","Configuration: 'criterion': gini, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': gini, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1 | 'Accuracy': 0.92\n","Configuration: 'criterion': gini, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2 | 'Accuracy': 0.90\n","Configuration: 'criterion': gini, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': gini, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1 | 'Accuracy': 0.90\n","Configuration: 'criterion': gini, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2 | 'Accuracy': 0.90\n","Configuration: 'criterion': gini, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': gini, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1 | 'Accuracy': 0.90\n","Configuration: 'criterion': gini, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2 | 'Accuracy': 0.89\n","Configuration: 'criterion': gini, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': gini, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 1 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 2 | 'Accuracy': 0.91\n","Configuration: 'criterion': gini, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1 | 'Accuracy': 0.91\n","Configuration: 'criterion': entropy, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2 | 'Accuracy': 0.94\n","Configuration: 'criterion': entropy, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2 | 'Accuracy': 0.94\n","Configuration: 'criterion': entropy, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1 | 'Accuracy': 0.91\n","Configuration: 'criterion': entropy, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2 | 'Accuracy': 0.94\n","Configuration: 'criterion': entropy, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1 | 'Accuracy': 0.91\n","Configuration: 'criterion': entropy, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2 | 'Accuracy': 0.94\n","Configuration: 'criterion': entropy, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2 | 'Accuracy': 0.94\n","Configuration: 'criterion': entropy, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 1 | 'Accuracy': 0.92\n","Configuration: 'criterion': entropy, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 2 | 'Accuracy': 0.93\n","Configuration: 'criterion': entropy, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 4 | 'Accuracy': 0.92\n","\n","-------------------------\n","Result:\n","Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}\n","Best accuracy: 0.935\n"]}]},{"cell_type":"markdown","source":["## Support Vector Machine"],"metadata":{"id":"HGnW2STcr81F"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","# Generating a synthetic dataset\n","X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define a list of hyperparameters to tune\n","hyperparameters = {\n","    'C': [0.1, 1, 10],\n","    'kernel': ['linear', 'rbf'],\n","    'gamma': ['scale', 'auto']\n","}\n","\n","best_accuracy = 0\n","best_params = {}\n","\n","# Perform grid search over the hyperparameters\n","for C in hyperparameters['C']:\n","    for kernel in hyperparameters['kernel']:\n","        for gamma in hyperparameters['gamma']:\n","            # Create the model with the current hyperparameters\n","            model = SVC(C=C, kernel=kernel, gamma=gamma)\n","\n","            # Train the model\n","            model.fit(X_train, y_train)\n","\n","            # Make predictions\n","            predictions = model.predict(X_test)\n","\n","            # Calculate accuracy\n","            accuracy = accuracy_score(y_test, predictions)\n","\n","            print(f\"Configuration: 'C': {C}, 'kernel': {kernel}, 'gamma': {gamma} | 'Accuracy': {accuracy:.2f}\")\n","\n","            # Check if this is the best parameter combination\n","            if accuracy > best_accuracy:\n","                best_accuracy = accuracy\n","                best_params = {'C': C, 'kernel': kernel, 'gamma': gamma}\n","\n","print(f\"\\n{'-'*25}\\nResult:\")\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best accuracy:\", best_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5diakyV6r9GK","executionInfo":{"status":"ok","timestamp":1699897366228,"user_tz":360,"elapsed":413,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"e3d6da61-ea4b-4acf-b0e3-660603323530"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration: 'C': 0.1, 'kernel': linear, 'gamma': scale | 'Accuracy': 0.85\n","Configuration: 'C': 0.1, 'kernel': linear, 'gamma': auto | 'Accuracy': 0.85\n","Configuration: 'C': 0.1, 'kernel': rbf, 'gamma': scale | 'Accuracy': 0.92\n","Configuration: 'C': 0.1, 'kernel': rbf, 'gamma': auto | 'Accuracy': 0.92\n","Configuration: 'C': 1, 'kernel': linear, 'gamma': scale | 'Accuracy': 0.84\n","Configuration: 'C': 1, 'kernel': linear, 'gamma': auto | 'Accuracy': 0.84\n","Configuration: 'C': 1, 'kernel': rbf, 'gamma': scale | 'Accuracy': 0.92\n","Configuration: 'C': 1, 'kernel': rbf, 'gamma': auto | 'Accuracy': 0.94\n","Configuration: 'C': 10, 'kernel': linear, 'gamma': scale | 'Accuracy': 0.85\n","Configuration: 'C': 10, 'kernel': linear, 'gamma': auto | 'Accuracy': 0.85\n","Configuration: 'C': 10, 'kernel': rbf, 'gamma': scale | 'Accuracy': 0.94\n","Configuration: 'C': 10, 'kernel': rbf, 'gamma': auto | 'Accuracy': 0.96\n","\n","-------------------------\n","Result:\n","Best hyperparameters: {'C': 10, 'kernel': 'rbf', 'gamma': 'auto'}\n","Best accuracy: 0.96\n"]}]},{"cell_type":"markdown","source":["## k-Nearest Neighbors"],"metadata":{"id":"iwGadQ5CwSoE"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Generating a synthetic dataset\n","X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define a list of hyperparameters to tune\n","hyperparameters = {\n","    'n_neighbors': [3, 5, 7, 9],\n","    'weights': ['uniform', 'distance'],\n","    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n","}\n","\n","best_accuracy = 0\n","best_params = {}\n","\n","# Perform grid search over the hyperparameters\n","for n_neighbors in hyperparameters['n_neighbors']:\n","    for weights in hyperparameters['weights']:\n","        for algorithm in hyperparameters['algorithm']:\n","            # Create the model with the current hyperparameters\n","            model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm)\n","\n","            # Train the model\n","            model.fit(X_train, y_train)\n","\n","            # Make predictions\n","            predictions = model.predict(X_test)\n","\n","            # Calculate accuracy\n","            accuracy = accuracy_score(y_test, predictions)\n","\n","            print(f\"Configuration: 'n_neighbors': {n_neighbors}, 'weights': {weights}, 'algorithm': {algorithm} | 'Accuracy': {accuracy:.2f}\")\n","\n","            # Check if this is the best parameter combination\n","            if accuracy > best_accuracy:\n","                best_accuracy = accuracy\n","                best_params = {'n_neighbors': n_neighbors, 'weights': weights, 'algorithm': algorithm}\n","\n","print(f\"\\n{'-'*25}\\nResult:\")\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best accuracy:\", best_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLpoyxJewSSY","executionInfo":{"status":"ok","timestamp":1699897366694,"user_tz":360,"elapsed":599,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"1481f58a-2f32-4b5e-caa3-ad01279c9d94"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration: 'n_neighbors': 3, 'weights': uniform, 'algorithm': auto | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 3, 'weights': uniform, 'algorithm': ball_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 3, 'weights': uniform, 'algorithm': kd_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 3, 'weights': uniform, 'algorithm': brute | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 3, 'weights': distance, 'algorithm': auto | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 3, 'weights': distance, 'algorithm': ball_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 3, 'weights': distance, 'algorithm': kd_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 3, 'weights': distance, 'algorithm': brute | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 5, 'weights': uniform, 'algorithm': auto | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 5, 'weights': uniform, 'algorithm': ball_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 5, 'weights': uniform, 'algorithm': kd_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 5, 'weights': uniform, 'algorithm': brute | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 5, 'weights': distance, 'algorithm': auto | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 5, 'weights': distance, 'algorithm': ball_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 5, 'weights': distance, 'algorithm': kd_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 5, 'weights': distance, 'algorithm': brute | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 7, 'weights': uniform, 'algorithm': auto | 'Accuracy': 0.93\n","Configuration: 'n_neighbors': 7, 'weights': uniform, 'algorithm': ball_tree | 'Accuracy': 0.93\n","Configuration: 'n_neighbors': 7, 'weights': uniform, 'algorithm': kd_tree | 'Accuracy': 0.93\n","Configuration: 'n_neighbors': 7, 'weights': uniform, 'algorithm': brute | 'Accuracy': 0.93\n","Configuration: 'n_neighbors': 7, 'weights': distance, 'algorithm': auto | 'Accuracy': 0.93\n","Configuration: 'n_neighbors': 7, 'weights': distance, 'algorithm': ball_tree | 'Accuracy': 0.93\n","Configuration: 'n_neighbors': 7, 'weights': distance, 'algorithm': kd_tree | 'Accuracy': 0.93\n","Configuration: 'n_neighbors': 7, 'weights': distance, 'algorithm': brute | 'Accuracy': 0.93\n","Configuration: 'n_neighbors': 9, 'weights': uniform, 'algorithm': auto | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 9, 'weights': uniform, 'algorithm': ball_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 9, 'weights': uniform, 'algorithm': kd_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 9, 'weights': uniform, 'algorithm': brute | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 9, 'weights': distance, 'algorithm': auto | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 9, 'weights': distance, 'algorithm': ball_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 9, 'weights': distance, 'algorithm': kd_tree | 'Accuracy': 0.92\n","Configuration: 'n_neighbors': 9, 'weights': distance, 'algorithm': brute | 'Accuracy': 0.92\n","\n","-------------------------\n","Result:\n","Best hyperparameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto'}\n","Best accuracy: 0.925\n"]}]},{"cell_type":"markdown","source":["## KMeans"],"metadata":{"id":"SoFV7j_1w_5T"}},{"cell_type":"code","source":["from sklearn.datasets import make_blobs\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","\n","# Generating a synthetic dataset\n","X, _ = make_blobs(n_samples=1000, centers=5, n_features=2, random_state=42)\n","\n","# Define a list of hyperparameters to tune\n","hyperparameters = {\n","    'n_clusters': [3, 4, 5, 6, 7],\n","    'init': ['k-means++', 'random']\n","}\n","\n","best_silhouette_score = -1\n","best_params = {}\n","\n","# Perform grid search over the hyperparameters\n","for n_clusters in hyperparameters['n_clusters']:\n","    for init in hyperparameters['init']:\n","        # Create the model with the current hyperparameters\n","        model = KMeans(n_clusters=n_clusters, init=init, random_state=42)\n","\n","        # Fit the model\n","        model.fit(X)\n","\n","        # Get cluster labels\n","        cluster_labels = model.labels_\n","\n","        # Calculate silhouette score (measure of how well-defined the clusters are)\n","        silhouette = silhouette_score(X, cluster_labels)\n","\n","        print(f\"Configuration: 'n_clusters': {n_clusters}, 'init': {init} | 'Silhouette Score': {silhouette:.4f}\")\n","\n","        # Check if this is the best parameter combination\n","        if silhouette > best_silhouette_score:\n","            best_silhouette_score = silhouette\n","            best_params = {'n_clusters': n_clusters, 'init': init}\n","\n","print(f\"\\n{'-'*25}\\nResult:\")\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best silhouette score:\", best_silhouette_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MXQaJMExALU","executionInfo":{"status":"ok","timestamp":1699897375959,"user_tz":360,"elapsed":9268,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"1774af16-979d-4a32-a752-399b898fa37d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration: 'n_clusters': 3, 'init': k-means++ | 'Silhouette Score': 0.7011\n","Configuration: 'n_clusters': 3, 'init': random | 'Silhouette Score': 0.7011\n","Configuration: 'n_clusters': 4, 'init': k-means++ | 'Silhouette Score': 0.7270\n","Configuration: 'n_clusters': 4, 'init': random | 'Silhouette Score': 0.7270\n","Configuration: 'n_clusters': 5, 'init': k-means++ | 'Silhouette Score': 0.6779\n","Configuration: 'n_clusters': 5, 'init': random | 'Silhouette Score': 0.6779\n","Configuration: 'n_clusters': 6, 'init': k-means++ | 'Silhouette Score': 0.5963\n","Configuration: 'n_clusters': 6, 'init': random | 'Silhouette Score': 0.5976\n","Configuration: 'n_clusters': 7, 'init': k-means++ | 'Silhouette Score': 0.4919\n","Configuration: 'n_clusters': 7, 'init': random | 'Silhouette Score': 0.4930\n","\n","-------------------------\n","Result:\n","Best hyperparameters: {'n_clusters': 4, 'init': 'k-means++'}\n","Best silhouette score: 0.7270405117710104\n"]}]},{"cell_type":"markdown","source":["# Hyperparameter Search\n","## GridSearch"],"metadata":{"id":"4PwE1matBgo9"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV"],"metadata":{"id":"B8NKG_WQYiuV","executionInfo":{"status":"ok","timestamp":1699897375960,"user_tz":360,"elapsed":25,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Linear Regresion"],"metadata":{"id":"faaF7DlLCnoK"}},{"cell_type":"code","source":["# Generating a synthetic dataset with 100 data points\n","X, y = make_regression(n_samples=100, n_features=20, noise=25, random_state=42)\n","\n","# Define the parameter grid for GridSearchCV\n","param_grid = {\n","    'fit_intercept': [True, False],\n","    'positive': [True, False]\n","}\n","\n","# Create the model\n","model = LinearRegression()\n","\n","# Perform grid search\n","grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n","grid_search.fit(X, y)\n","\n","# Get the best parameters and the best score\n","best_params = grid_search.best_params_\n","best_score = -grid_search.best_score_\n","\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best mean squared error:\", best_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K_D6miiUYhBe","executionInfo":{"status":"ok","timestamp":1699897376081,"user_tz":360,"elapsed":145,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"68cda512-afe9-45b9-e0af-632cb30826af"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'fit_intercept': False, 'positive': True}\n","Best mean squared error: 722.8188373406498\n"]}]},{"cell_type":"markdown","source":["## Logistic Regression"],"metadata":{"id":"gkmZkVdKCqvo"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","\n","# Generating a synthetic dataset\n","X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n","\n","# Define a parameter grid for GridSearchCV\n","param_grid = {\n","    'penalty': ['l1', 'l2'],\n","    'C': [0.001, 0.01, 0.1, 1, 10]\n","}\n","\n","# Create the model\n","model = LogisticRegression(solver='liblinear')\n","\n","# Perform grid search\n","grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X, y)\n","\n","# Get the best parameters and the best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best accuracy:\", best_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTRpR_TOY3X8","executionInfo":{"status":"ok","timestamp":1699897376508,"user_tz":360,"elapsed":430,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"fa62d2b8-3984-4f00-d8b7-888e125404c0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'C': 0.1, 'penalty': 'l1'}\n","Best accuracy: 0.8210000000000001\n"]}]},{"cell_type":"markdown","source":["## Decision Tree Classifier"],"metadata":{"id":"sTS4Y1-urQmp"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Generating a synthetic dataset\n","X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n","\n","# Define a parameter grid for GridSearchCV\n","param_grid = {\n","    'criterion': ['gini', 'entropy'],\n","    'max_depth': [None, 5, 10, 15],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Create the model\n","model = DecisionTreeClassifier()\n","\n","# Perform grid search\n","grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X, y)\n","\n","# Get the best parameters and the best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best accuracy:\", best_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pmOgVW7rQ2H","executionInfo":{"status":"ok","timestamp":1699897380175,"user_tz":360,"elapsed":3671,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"51461da8-f4b0-4fa3-d19d-1b7009204f7f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n","Best accuracy: 0.916\n"]}]},{"cell_type":"markdown","source":["## Suport Vector Machine"],"metadata":{"id":"rPUiPI59sOBT"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.svm import SVC\n","\n","# Generating a synthetic dataset\n","X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define a parameter grid for GridSearchCV\n","param_grid = {\n","    'C': [0.1, 1, 10],\n","    'kernel': ['linear', 'rbf'],\n","    'gamma': ['scale', 'auto']\n","}\n","\n","# Create the model\n","model = SVC()\n","\n","# Perform grid search\n","grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X, y)\n","\n","# Get the best parameters and the best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best accuracy:\", best_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQYc5XEbsOPN","executionInfo":{"status":"ok","timestamp":1699897382471,"user_tz":360,"elapsed":2320,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"8ed32915-901d-4361-93c6-212fcaca67b0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n","Best accuracy: 0.9349999999999999\n"]}]},{"cell_type":"markdown","source":["## k-Nearest Neighbors"],"metadata":{"id":"KjD5AGD5wyXh"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Generating a synthetic dataset\n","X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define a parameter grid for GridSearchCV\n","param_grid = {\n","    'n_neighbors': [3, 5, 7, 9],\n","    'weights': ['uniform', 'distance'],\n","    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n","}\n","\n","# Create the model\n","model = KNeighborsClassifier()\n","\n","# Perform grid search\n","grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X, y)\n","\n","# Get the best parameters and the best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best accuracy:\", best_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJpsWV-JwylO","executionInfo":{"status":"ok","timestamp":1699897384993,"user_tz":360,"elapsed":2524,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"ba480e2a-2866-40a5-b4d4-e80f7dc5849f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'}\n","Best accuracy: 0.9179999999999999\n"]}]},{"cell_type":"markdown","source":["## KMeans"],"metadata":{"id":"BGkRDQ1-xYHh"}},{"cell_type":"code","source":["from sklearn.datasets import make_blobs\n","from sklearn.cluster import KMeans\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import silhouette_score\n","\n","# Generating a synthetic dataset\n","X, _ = make_blobs(n_samples=1000, centers=5, n_features=2, random_state=42)\n","\n","# Define a parameter grid for GridSearchCV\n","param_grid = {\n","    'n_clusters': [3, 4, 5, 6, 7],\n","    'init': ['k-means++', 'random']\n","}\n","\n","# Create the model\n","model = KMeans()\n","\n","# Perform grid search\n","grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error')  # Use an appropriate metric for evaluation\n","grid_search.fit(X)\n","\n","# Get the best parameters and the best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(\"Best hyperparameters:\", best_params)\n","print(\"Best score (neg_mean_squared_error):\", best_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ivfos3eUxYTg","executionInfo":{"status":"ok","timestamp":1699897385794,"user_tz":360,"elapsed":806,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"f25e01ea-a240-41ef-a8bf-495934f13722"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'init': 'k-means++', 'n_clusters': 3}\n","Best score (neg_mean_squared_error): nan\n"]}]},{"cell_type":"markdown","source":["# Optimization Algorithm"],"metadata":{"id":"eD9sDcVgyUBA"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Generating some random data\n","np.random.seed(42)\n","X = 2 * np.random.rand(100, 1)\n","y = 4 + 3 * X + np.random.randn(100, 1)\n","\n","\n","def gradient_descent(X, y, learning_rate, n_iterations):\n","    m = X.shape[0]  # number of instances\n","    theta = np.random.randn(2, 1)  # random initialization of theta (including bias term)\n","    X_b = np.c_[np.ones((m, 1)), X]  # adding bias term to features\n","\n","    for iteration in range(n_iterations):\n","        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n","        theta -= learning_rate * gradients\n","\n","    return theta\n","\n","\n","learning_rate = 0.1\n","n_iterations = 1000\n","\n","theta = gradient_descent(X, y, learning_rate, n_iterations)\n","print(\"Optimal theta (bias, coefficient):\", theta.ravel())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOLagJZy2jjQ","executionInfo":{"status":"ok","timestamp":1699898876655,"user_tz":360,"elapsed":143,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"74ec6c25-b90c-4320-8c2d-ea9d75ce3a45"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimal theta (bias, coefficient): [4.21509616 2.77011339]\n"]}]},{"cell_type":"markdown","source":["## Using Sklearn"],"metadata":{"id":"jTxQ6UU_3q-0"}},{"cell_type":"code","source":["from sklearn.datasets import make_regression\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","# Generate a synthetic dataset\n","X, y = make_regression(n_samples=1000, n_features=1000, noise=50, random_state=42)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create and train the linear regression model without gradient descent\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","predictions = model.predict(X_test)\n","\n","# Calculate mean squared error\n","mse = mean_squared_error(y_test, predictions)\n","r2 = model.score(X_test, y_test)\n","print(\"Mean Squared Error (without Gradient Descent):\", mse)\n","print(\"R2 (without Gradient Descent):\", r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2CEtVSWyfWw","executionInfo":{"status":"ok","timestamp":1699898594795,"user_tz":360,"elapsed":340,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"3f6699b4-6bbd-486f-a0b0-407dbddfeab0"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error (without Gradient Descent): 20552.995779983765\n","R2 (without Gradient Descent): 0.4159166755545346\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import SGDRegressor\n","from sklearn.preprocessing import StandardScaler\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Create and train the linear regression model with gradient descent\n","model = SGDRegressor(loss='huber', max_iter=1000, learning_rate='optimal')\n","model.fit(X_train_scaled, y_train)\n","\n","# Make predictions\n","predictions = model.predict(X_test_scaled)\n","\n","# Calculate mean squared error\n","mse = mean_squared_error(y_test, predictions)\n","r2 = model.score(X_test_scaled, y_test)\n","print(\"Mean Squared Error (with Gradient Descent):\", mse)\n","print(\"R2 (with Gradient Descent):\", r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8_dAu-My_-_","executionInfo":{"status":"ok","timestamp":1699898596103,"user_tz":360,"elapsed":500,"user":{"displayName":"Andrei Noguera Gil","userId":"10150960277856069898"}},"outputId":"3866365f-e9ef-4dde-bdef-71c62dc2b4b8"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error (with Gradient Descent): 17577.659440818334\n","R2 (with Gradient Descent): 0.5004709837890357\n"]}]}]}